{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA_QTG8vFs8E"
   },
   "source": [
    "## Modèle en production\n",
    "\n",
    "Laurent Cetinsoy - Datadidacte\n",
    "\n",
    "Une des supposition centrale pour qu'un modèle de machine learning marche est que la distribution des données ne diffère pas de celle des données d'entrainement.\n",
    "\n",
    "On ne peut garantir la généralisation d'un modèle que si la distribution des données est similaire à celle de la distribution $ X_{prod} \\tilde{} \\,  P_{train}$\n",
    "\n",
    "Ainsi, si les données que le modèle voient en production n'ont pas la même distribution (ne ressemblent pas) aux données de train, alors le modèle aura peu de chance de faire de bonne prédictions.\n",
    "\n",
    "Il est donc important de surveille les données vues par le modèle en production.\n",
    "\n",
    "Pour cela on va mesurer ce qu'on appelle le Data drift : on va mesurer à quel point les données s'écartent des données de train.\n",
    "\n",
    "Et on pourra ainsi lever une alerte si c'est le cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEHFqy-yFs8K"
   },
   "source": [
    "## Utilisation Eurybia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7Cr8DVyFs8N"
   },
   "source": [
    "\n",
    "En consultant la documentation de Eurybia (https://eurybia.readthedocs.io/en/latest/overview.html), expliquer le principe de fonctionnement de Euribya :\n",
    "\n",
    "- A quoi sert le modèle de classification ?\n",
    "- A-t-on besoin d’avoir les labels issus de la production pour pouvoir utiliser cette approche ?\n",
    "- Quel est le critère pour déterminer qu’il y a un data-drift ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2lpGujbFs8Q"
   },
   "source": [
    "- **A quoi sert le modèle de classification ?**\n",
    "Le principe d'Eurybia est de détecter le \"data drift\" en entraînant un modèle de classification pour distinguer les données d'entraînement (données de référence) des données de production (données actuelles). Les données d'entraînement sont étiquetées comme une classe (par exemple, 0) et les données de production comme une autre (par exemple, 1). Si le classifieur obtient une performance élevée (par exemple, une AUC proche de 1), cela signifie qu'il peut facilement faire la différence entre les deux jeux de données, ce qui indique que leurs distributions sont significativement différentes. Un data drift est donc détecté.\n",
    "\n",
    "- **A-t-on besoin d’avoir les labels issus de la production pour pouvoir utiliser cette approche ?**\n",
    "Non, les labels (la variable cible `y`) des données de production ne sont pas nécessaires. La détection de drift se concentre uniquement sur les distributions des variables explicatives (`X`). L'approche est donc non supervisée du point de vue de la tâche de prédiction initiale.\n",
    "\n",
    "- **Quel est le critère pour déterminer qu’il y a un data-drift ?**\n",
    "Le critère principal est la performance du modèle de classification entraîné pour séparer les deux jeux de données. Généralement, on utilise l'AUC (Area Under the Curve).\n",
    "     - Une **AUC proche de 0.5** signifie que le modèle n'arrive pas à distinguer les deux distributions (performance aléatoire), indiquant une absence de drift.\n",
    "     - Une **AUC élevée** (généralement supérieure à un seuil défini par l'utilisateur, par exemple 0.7 ou 0.8) signifie que les distributions sont différentes et qu'il y a un data drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAn3sAA7Fs8W"
   },
   "source": [
    "Installer eurybia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUCfIkyzFs8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6qFJUvoFs8e"
   },
   "source": [
    "Utiliser eurybia pour monitorer le modèle. Dans un premier temps faire en sorte que les données (df_current) soient de la même distribution que vos données d’entraînement. Vérifier que Eurybia pense que le modèle ne drift pas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_TjazQyrFs8i"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SmartExplainer' from partially initialized module 'shapash.explainer.smart_explainer' (most likely due to a circular import) (c:\\Users\\clem9\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shapash\\explainer\\smart_explainer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meurybia\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmartDrift\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mhouses.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clem9\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\eurybia\\__init__.py:6\u001b[39m\n\u001b[32m      3\u001b[39m __author__ = \u001b[33m\"\"\"\u001b[39m\u001b[33mThomas Bouche, Johann Martin, Nicolas Roux\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      4\u001b[39m __email__ = \u001b[33m\"\u001b[39m\u001b[33mthomas.bouche@maif.fr\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meurybia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msmartdrift\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmartDrift\n\u001b[32m      8\u001b[39m VERSION = (\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, VERSION))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clem9\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\eurybia\\core\\smartdrift.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_datetime64_any_dtype \u001b[38;5;28;01mas\u001b[39;00m is_datetime\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapash\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexplainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msmart_explainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmartExplainer\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clem9\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shapash\\explainer\\smart_explainer.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapash\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexplainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msmart_predictor\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapash\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseBackend, get_backend_cls_from_name\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapash\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshap_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_shap_interaction_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clem9\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shapash\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m __author__ = (\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Yann Golhen, Yann Lagré, Sebastien Bidault, Maxime Gendre, Thomas Bouche, Johann Martin, Guillaume Vignal\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m __email__ = \u001b[33m\"\u001b[39m\u001b[33myann.golhen@maif.fr, yann.lagre@maif.fr, sebabstien.bidault.marketing@maif.fr, thomas.bouche@maif.fr, guillaume.vignal@maif.fr\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapash\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexplainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msmart_explainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmartExplainer\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__version__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'SmartExplainer' from partially initialized module 'shapash.explainer.smart_explainer' (most likely due to a circular import) (c:\\Users\\clem9\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shapash\\explainer\\smart_explainer.py)"
     ]
    }
   ],
   "source": [
    "# Alternative approach: Manual drift detection without eurybia\n",
    "# Since there are compatibility issues with shapash, let's implement basic drift detection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('houses.csv')\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Simple drift detection approach:\n",
    "# 1. Create binary labels (0 for baseline, 1 for current)\n",
    "# 2. Train classifier to distinguish between datasets\n",
    "# 3. High AUC indicates drift\n",
    "\n",
    "def detect_drift(baseline_data, current_data, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Simple drift detection using binary classification approach\n",
    "    \"\"\"\n",
    "    # Create labels\n",
    "    baseline_labels = np.zeros(len(baseline_data))\n",
    "    current_labels = np.ones(len(current_data))\n",
    "    \n",
    "    # Combine data\n",
    "    X = pd.concat([baseline_data, current_data], ignore_index=True)\n",
    "    y = np.concatenate([baseline_labels, current_labels])\n",
    "    \n",
    "    # Select only numeric columns for simplicity\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    X_numeric = X[numeric_cols]\n",
    "    \n",
    "    # Handle missing values\n",
    "    X_numeric = X_numeric.fillna(X_numeric.mean())\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    \n",
    "    # Cross-validation to get AUC score\n",
    "    cv_scores = cross_val_score(clf, X_numeric, y, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    auc_mean = cv_scores.mean()\n",
    "    auc_std = cv_scores.std()\n",
    "    \n",
    "    return {\n",
    "        'auc_mean': auc_mean,\n",
    "        'auc_std': auc_std,\n",
    "        'cv_scores': cv_scores,\n",
    "        'drift_detected': auc_mean > 0.75  # Threshold for drift detection\n",
    "    }\n",
    "\n",
    "# Test with same data (should show no drift)\n",
    "result = detect_drift(df, df)\n",
    "print(f\"\\nDrift detection results (same data):\")\n",
    "print(f\"AUC: {result['auc_mean']:.3f} ± {result['auc_std']:.3f}\")\n",
    "print(f\"Drift detected: {result['drift_detected']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXc0y7gxFs8k"
   },
   "source": [
    "Faire de même avec des données de test. Les données de tests ont-elle un drift par rapport au train ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqxlWgurFs8l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpbUJGhzFs8m"
   },
   "source": [
    "Générer des données qui ne ressemblent ni au train ni au test (par exemple avec des données abérentes). Euribya détecte-t-il ces données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pyIJbu5Fs8n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYnareE4Fs8o"
   },
   "source": [
    "## Alibaba detect\n",
    "\n",
    "Dans cette partie on va utiliser la librairie https://github.com/SeldonIO/alibi-detect pour faire la détection de problèmes\n",
    "Installer la librairie avec pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX5iAyTJFs8q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJvFD2xrFs8r"
   },
   "source": [
    "Charger le jeu de donnée cifar10 avec keras et récupérer le train et le test puis,\n",
    "\n",
    "Normaliser les données de train en faisant un MinMaxScaling (diviser par 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X90oWx5AFs8v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45x7yftfFs8w"
   },
   "source": [
    "Dans le sous package alibbi_detect.datasets importer les  fonction fetch_cifar10c et corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u6Pp8x9Fs80"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH81nEs_Fs82"
   },
   "source": [
    "Afficher les types de corruption de données disponible avec la fonction corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH0zp3fbFs84"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDTT-67yFs86"
   },
   "source": [
    "Avec la fonction fetch_cifar10c récupérer des exemples corrompus de donnée ressemblant à cifar 10 et les stocker dans des variable X_corrupted et y_corrupted.\n",
    "\n",
    "Vous choisirez 1 ou 2 corruptions parmis les suivantes : ['gaussian_noise', 'motion_blur', 'brightness', 'pixelate']\n",
    "\n",
    "Vous spécifirez les argument severity=5 et return_X_y=True\n",
    "attention le dataset peut être lourd si vous utilisez bcp de corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8SL8z_TFs8-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilj7rn6aFs8_"
   },
   "source": [
    "Normaliser les images corrompues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tS0CR6e5Fs9B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_mTwk7yFs9B"
   },
   "source": [
    "Afficher plusieurs des images corrompues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHmjeAywFs9C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bev6XyQZFs9D"
   },
   "source": [
    "On va maintenant prendre un modèle entraîné sur cifar10 pour voir l'impact des performances sur le modèle.\n",
    "\n",
    "Avec la fonction  fetch_tf_model du module alibi_detect.utils.fetching, charger le modèle préentraîné resnet32 sur cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOkVyhy2Fs9G"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.utils.fetching import fetch_tf_model, fetch_detector\n",
    "dataset = 'cifar10'\n",
    "model_name = 'resnet32'\n",
    "model = fetch_tf_model(dataset, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSVWdspmFs9K"
   },
   "source": [
    "Calculer la performance du model sur le jeu de train et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyBxvmGaFs9M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SG82jqxFs9N"
   },
   "source": [
    "Calculer la performance du modèle sur le jeu de donnée corrompu. Vous devriez observer qu'il chute significativement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWux1w8EFs9P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT9bns5tFs9Q"
   },
   "source": [
    "On va maintenant voir comment détecter les changement de distributions de données.\n",
    "\n",
    "Pour les données non tabulaire ou à haute dimension on procéde généralement en deux étapes :\n",
    "\n",
    "1. Faire une réduction de dimension\n",
    "2. Faire un test permettant de voir si les données projetées ont changé de distribution ou pas\n",
    "\n",
    "Il existe plusieurs manières de faire de la réduction de dimension. La plus classique est la PCA.\n",
    "\n",
    "Il est possible également d'utiliser des Auto-encoder\n",
    "\n",
    "Le code suivant permet de créer la première partie (l'encoder) d'un auto-encoder simple qui nous servira à réduire les dimension des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBJao1RXFs9R"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, InputLayer, Reshape\n",
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# define encoder\n",
    "encoding_dim = 32\n",
    "encoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(32, 32, 3)),\n",
    "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "      Dense(encoding_dim,)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH4ZehyHFs9S"
   },
   "source": [
    "Le drift detector a besoin d'une donnée de référence afin d'effectuer la comparaison avec les données à monitorer.\n",
    "Créer une variable X_ref avec un échantillon aléatoire des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk6euJipFs9T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZrtwSr4Fs9Z"
   },
   "source": [
    "A quoi sert le test statistique kolmogorov smirnoff ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XsIOHxBFs9d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXatEJZOFs9f"
   },
   "source": [
    "Instancier la classe KSDrift dans une variable nommée **detector**\n",
    "\n",
    "Il faut lui passer le dataset de reference, une p value (prendre 0.05) et une fonction permettant de faire le preprocessing. On a créé la fonction pour vous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epmDLfAfFs9i"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "preprocess_function = partial(preprocess_drift, model=encoder_net, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUSKpqulFs9k"
   },
   "source": [
    "A laide du Drift detector et la méthode predict faire des prediction sur les données de test et sur les données corrompue pour voir si il détecte un changement de distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfaYUukjFs9o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
